#+title: Todo

* architecture
** TODO handle images!
** TODO extend the tokeniser to handle skippable things
** DONE break lemma type into lemma_id + fk to a variant type (id, lemma_id, spelling, reading)
** DONE surface forms must be associated to a variant_id rather than a lemma_id
*** alternatively variant (id, spelling, reading) + lemmas_variants (lemma_id, variant_id) + etc
** kanji table
** reading table
** id, kanji_id, reading_id join table
*** this modeling additionally allows us to link "similar" kanji: which ones appear with identical readings in the same lemmas?
** variant, index (for ordering of links), kanji_reading_id table
** variant has fsrs card (??) so this will allow link computation
*** would be a first form of srs linking/influence
*** alt, we could start with srs on lemmas and join through the variant table
** DONE get rid of sqlx migrations and instead have something like
#+begin_src rust
Def::create_table();
Def::create_indexes();
Def::drop_indexes();
#+end_src
etc to make consistency with "migrations" easier given we are procedurally dropping and recreating indexes everywhere

* small features
** read yomichan dict names from the index.json

* features
** DONE smaller crates
** DONE move to pg
** TODO yomichan: use dict name from index.json
** TODO fix the handling of fallbacks when searching for word info
Ideally you'd want something that keeps the first of all the options that maximises definition count. In particular, the first that gets you 0.
** TODO book "collections" and starred sentence display being limited to collections
** TODO replace the css for every instance of a word when doing a review
*** although with js you could just change css for one class
** TODO ping the reader when a review comes up :)
** TODO parallelise epub reading
** symbols, readings, symbol_readings (id, language, symbol, reading)
** term_symbol_readings (id, term_id, symbol_reading_id)
